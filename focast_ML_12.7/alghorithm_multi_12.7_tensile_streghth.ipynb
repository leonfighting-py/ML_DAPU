{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffc035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import LeaveOneOut, KFold, cross_val_predict,RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, Matern, ConstantKernel as C,DotProduct, RationalQuadratic\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置绘图风格\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # 显示中文\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b150c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pearson和ANOVA特征计算用，先放着，暂时没用\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# --- A. Pearson 相关系数 ---\n",
    "plt.figure(figsize=(10, 8))\n",
    "# 计算特征与目标，以及特征之间的相关性\n",
    "correlation_matrix = df[features + [target]].corr(method='pearson')\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Pearson Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# --- B. ANOVA (F-test) 特征重要性评分 ---\n",
    "# f_regression 适用于回归问题，计算每个特征与目标的 F-value\n",
    "f_scores, p_values = f_regression(X, y)\n",
    "\n",
    "# 创建结果表\n",
    "anova_results = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'F_Score': f_scores,\n",
    "    'P_Value': p_values\n",
    "})\n",
    "# 按 F_Score 降序排列\n",
    "anova_results = anova_results.sort_values(by='F_Score', ascending=False)\n",
    "\n",
    "print(\"\\n=== ANOVA (F-test) Feature Importance ===\")\n",
    "print(anova_results)\n",
    "\n",
    "# 解读：\n",
    "# F_Score 越高，说明该特征与目标变量的线性依赖关系越强。\n",
    "# P_Value < 0.05 说明该相关性在统计学上是显著的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fabea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始准备工作\n",
    "# 1.读取清洗好的数据\n",
    "file_path = \"Final_Features_12.7.csv\" \n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ddbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.定义特征组\n",
    "# 力学特征\n",
    "features_mech = [\n",
    "    'X1_SoftSeg', 'X2_DA_Content', 'X3_HardSeg', 'X4_R_Ratio', 'X5_Crosslink', \n",
    "    'DA_strategy', 'cross_class',\n",
    "    'Polyol_Type', 'Polyol_Mw_Score', 'Soft_Cryst',\n",
    "    'Iso_Type', 'Hard_Symmetry', \n",
    "    'Interact_Cryst_Content', 'Synergy_Feature'\n",
    "]\n",
    "# 愈合特征\n",
    "features_heal = features_mech + ['healing_temperature', 'healing_time']\n",
    "\n",
    "# 3. 二次清洗\n",
    "def get_clean_data(target_col, feature_cols, df):\n",
    "    # 剔除空值\n",
    "    data = df.dropna(subset=[target_col] + feature_cols).copy()\n",
    "    X = data[feature_cols].values\n",
    "    y = data[target_col].values\n",
    "    return X, y\n",
    "\n",
    "# 4. 定义评估函数 \n",
    "def evaluate_model(model, X, y, task_name=\"Task\"):\n",
    "    # 使用 LOOCV (留一法) 适合小样本\n",
    "    cv = LeaveOneOut() \n",
    "    \n",
    "    # 预测\n",
    "    # 注意：对于 SVR/ANN 等对尺度敏感的模型，我们在 Pipeline 里已经封装了 Scaler，\n",
    "    # 但为了保险，这里建议外部也可以统一 Scale，或者依赖模型内部的 Pipeline\n",
    "    y_pred = cross_val_predict(model, X, y, cv=cv, n_jobs=-1)\n",
    "    \n",
    "    r2 = r2_score(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    return r2, rmse, y_pred\n",
    "\n",
    "print(\"环境设置完毕，特征组已定义。\")\n",
    "print(\"数据概览 (前5行):\")\n",
    "print(df[features_mech].head())\n",
    "print(f\"\\n有效总样本数: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4438460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 确定原本的数据集\n",
    "original_df = df.copy()\n",
    "\n",
    "# 2. 确定你目前使用的特征列表\n",
    "# (确保这里的 features_mech 是你实际传入模型的列表)\n",
    "features_to_check = features_mech\n",
    "\n",
    "# 3. 检查缺失情况\n",
    "print(f\"原始数据行数: {len(original_df)}\")\n",
    "\n",
    "# 筛选出含有 NaN 的行（即被删除的行）\n",
    "dropped_rows = original_df[original_df[features_to_check].isna().any(axis=1)]\n",
    "\n",
    "print(f\"被删除的数据行数: {len(dropped_rows)}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if len(dropped_rows) > 0:\n",
    "    print(\"以下样本因存在缺失值而被剔除：\")\n",
    "    # 显示 sample_id 和 具体缺失的列\n",
    "    # 假设你有一列叫 'sample_id'，如果没有请删掉 'sample_id'\n",
    "    cols_to_show = ['sample_id'] + features_to_check\n",
    "    \n",
    "    # 仅展示确实有缺失值的列，方便查看\n",
    "    for index, row in dropped_rows.iterrows():\n",
    "        missing_cols = [col for col in features_to_check if pd.isna(row[col])]\n",
    "        sample_id = row.get('sample_id', f'Row_{index}')\n",
    "        print(f\"样本 ID: {sample_id} -> 缺失字段: {missing_cols}\")\n",
    "else:\n",
    "    print(\"奇怪，没有发现缺失值。请检查是否使用了 train_test_split 划分了验证集？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPR\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "target_col = 'tensile_strength'\n",
    "features = features_mech\n",
    "X, y = get_clean_data(target_col, features, df)\n",
    "\n",
    "print(f\"开始进行GPR模型运算 (样本数: {len(y)})...\")\n",
    "\n",
    "# 定义核函数\n",
    "kernel = C(1.0, (1e-5, 1e5)) * \\\n",
    "         Matern(length_scale=1.0, length_scale_bounds=(1e-3, 1e4), nu=2.5) + \\\n",
    "         WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-5, 1e1))\n",
    "\n",
    "#  定义模型 \n",
    "gpr_model = make_pipeline(\n",
    "    StandardScaler(),  # 标准化特征 X\n",
    "    GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        n_restarts_optimizer=10,  # 重启10次防止局部最优\n",
    "        random_state=42,\n",
    "        normalize_y=True       \n",
    "    )\n",
    ")\n",
    "\n",
    "# 模型性能评估\n",
    "r2, rmse, y_pred_gpr = evaluate_model(gpr_model, X, y, task_name=\"GPR (Fixed)\")\n",
    "\n",
    "print(f\"=== GPR结果 ({target_col}) ===\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# 预测图绘制\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(y, y_pred_gpr, alpha=0.7, c='royalblue', edgecolors='k', label='Prediction')\n",
    "# 拟合直线\n",
    "min_val, max_val = min(y.min(), y_pred_gpr.min()), max(y.max(), y_pred_gpr.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Fit')\n",
    "\n",
    "plt.xlabel(f'Measured {target_col}')\n",
    "plt.ylabel(f'Predicted {target_col}')\n",
    "plt.title(f'GPR Prediction (Fixed)\\nR2={r2:.2f}, RMSE={rmse:.2f}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPR\n",
    "# 计算特征重要性\n",
    "# 全量拟合一次模型\n",
    "gpr_model.fit(X, y)\n",
    "\n",
    "print(\"\\n正在计算排列重要性 (Permutation Importance)...\")\n",
    "# n_repeats、random_state参数设置保证结果可复现\n",
    "r = permutation_importance(gpr_model, X, y, n_repeats=30, random_state=42, scoring='r2')\n",
    "\n",
    "# 获取重要性均值\n",
    "importances = r.importances_mean\n",
    "# 排序\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"\\n[特征重要性排行 (基于 R2 损失)]\")\n",
    "print(\"(数值代表：如果没有这个特征，R2 会下降多少)\")\n",
    "top_features = []\n",
    "for i in range(len(features)):\n",
    "    idx = indices[i]\n",
    "    # 只显示正贡献的特征\n",
    "    if importances[idx] > 0:\n",
    "        print(f\"{i+1}. {features[idx]}: {importances[idx]:.4f}\")\n",
    "        top_features.append((features[idx], importances[idx]))\n",
    "\n",
    "# 特征图绘制\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(f\"Feature Importance (Permutation) - Target: {target_col}\", fontsize=14)\n",
    "plt.bar(range(len(top_features)), [val for name, val in top_features], color='cornflowerblue', align=\"center\")\n",
    "plt.xticks(range(len(top_features)), [name for name, val in top_features], rotation=45, ha='right')\n",
    "plt.ylabel(\"Decrease in R2 Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be079e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "target_col = 'tensile_strength'  \n",
    "features = features_mech          \n",
    "X, y = get_clean_data(target_col, features, df)\n",
    "\n",
    "# 获取数据\n",
    "X, y = get_clean_data(target_col, features, df)\n",
    "\n",
    "# 定义模型\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=350,      # 树的数量\n",
    "    max_depth=10,        # 树的最大深度\n",
    "    min_samples_split=5,   # 节点分裂所需的最小样本数\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 评估\n",
    "print(\"正在进行 LOOCV 交叉验证评估精度...\")\n",
    "y_pred = cross_val_predict(rf_model, X, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "r2 = r2_score(y, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(f\"=== Random Forest 结果 ({target_col}) ===\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# 全量拟合一次模型\n",
    "print(\"\\n正在全量拟合模型 (为 SHAP 做准备)...\")\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y, y_pred, color='teal', alpha=0.6)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
    "plt.title(f\"RF Prediction (R2={r2:.2f})\")\n",
    "plt.xlabel(\"True Value\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e46db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# --- SHAP 分析 ---\n",
    "# 对于随机森林，SHAP 计算量比 XGBoost 大\n",
    "print(\"正在计算 Random Forest 的 SHAP 值...\")\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "# 如果报错，尝试: shap_values = explainer.shap_values(X)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(f\"RF - SHAP Summary for {target_col}\")\n",
    "# 处理 shap_values 格式兼容性 \n",
    "if isinstance(shap_values, list): # 针对分类任务或旧版\n",
    "    sv = shap_values[1]\n",
    "else:\n",
    "    sv = shap_values\n",
    "\n",
    "shap.summary_plot(sv, X, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac70ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "target_col = 'tensile_strength' \n",
    "features = features_mech\n",
    "X, y = get_clean_data(target_col, features, df)\n",
    "\n",
    "# --- 2. 定义参数字典 (注意：这里是字典 dict，不是模型对象) ---\n",
    "xgb_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "    # 'device': 'cuda' # 如果有显卡，取消注释这一行\n",
    "}\n",
    "\n",
    "# --- 3. 手写 LOOCV 循环 (同时收集 预测值 和 SHAP值) ---\n",
    "print(f\"正在进行严谨的 CV-SHAP 计算 (样本数: {len(y)})...\")\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "y_pred_cv = np.zeros(len(y)) # 存放预测结果\n",
    "shap_values_cv = []          # 存放 SHAP 结果\n",
    "indices_cv = []              # 记录顺序，防止乱序\n",
    "\n",
    "# 遍历每一个样本\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    # A. 切分数据\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # B. 训练模型 (只用训练集!)\n",
    "    model = XGBRegressor(**xgb_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # C. 预测 (为了算 R2)\n",
    "    pred = model.predict(X_test)\n",
    "    y_pred_cv[test_idx] = pred\n",
    "    \n",
    "    # D. 计算 SHAP (为了解释)\n",
    "    # 注意：我们要解释的是模型对“测试集”的判断逻辑\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_val = explainer.shap_values(X_test)\n",
    "    \n",
    "    # E. 收集结果\n",
    "    shap_values_cv.append(shap_val[0]) # LOOCV每次只有1个样本\n",
    "    indices_cv.append(test_idx[0])\n",
    "\n",
    "# 将 SHAP list 转为矩阵\n",
    "shap_values_cv = np.array(shap_values_cv)\n",
    "\n",
    "# --- 4. 结果汇总 ---\n",
    "# 真实的 R2 (基于 LOOCV)\n",
    "r2_real = r2_score(y, y_pred_cv)\n",
    "rmse_real = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "\n",
    "print(f\"\\n=== 最终结果 (基于 LOOCV) ===\")\n",
    "print(f\"✅ 真实泛化 R2: {r2_real:.4f}\")\n",
    "print(f\"✅ 真实泛化 RMSE: {rmse_real:.4f}\")\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(y, y_pred_cv, color='purple', alpha=0.6, label='CV Prediction')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', label='Perfect Fit')\n",
    "plt.title(f\"Real XGBoost Performance\\nR2={r2_real:.2f}\")\n",
    "plt.xlabel(\"Measured\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ae981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 5. 真实的 SHAP 绘图 ---\n",
    "print(\"\\n生成 CV-SHAP 图 (解释的是模型如何预测未知样本)...\")\n",
    "\n",
    "# 图1: 蜜蜂图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(f\"CV-SHAP Summary (Generalization Logic)\", fontsize=16)\n",
    "shap.summary_plot(shap_values_cv, X, feature_names=features, show=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 图2: 依赖图 (看新特征)\n",
    "if 'Iso_Type' in features:\n",
    "    shap.dependence_plot('Iso_Type', shap_values_cv, X, feature_names=features, interaction_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc4275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR\n",
    "target_col = 'tensile_strength'\n",
    "features = features_mech\n",
    "X, y = get_clean_data(target_col, features, df)\n",
    "\n",
    "# --- 2. 定义参数网格 ---\n",
    "# SVR 的三个核心参数：\n",
    "# C: 惩罚系数。越大越不容忍误差（容易过拟合），越小越平滑（容易欠拟合）。\n",
    "# gamma: 核函数宽度。越大越关注局部细节，越小越关注全局趋势。\n",
    "# epsilon: 对误差的容忍带宽度。\n",
    "param_grid = {\n",
    "    'svr__C': [1, 10, 50, 100, 500, 1000], \n",
    "    'svr__gamma': ['scale', 0.001, 0.01, 0.1, 0.5, 1.0],\n",
    "    'svr__epsilon': [0.01, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "# --- 3. 网格搜索 (GridSearchCV) ---\n",
    "# 建立 Pipeline\n",
    "pipe = make_pipeline(StandardScaler(), SVR(kernel='rbf'))\n",
    "\n",
    "# 使用 LOOCV 进行搜索 (保证和小样本验证逻辑一致)\n",
    "# scoring='neg_mean_squared_error' 表示寻找 MSE 最小的组合\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid, \n",
    "    cv=LeaveOneOut(), # 如果觉得太慢，可以改为 cv=5\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_svr = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"\\n[最佳参数组合]\")\n",
    "print(best_params)\n",
    "\n",
    "# --- 4. 使用最佳参数进行最终预测 (LOOCV) ---\n",
    "# 为了严谨，我们用在这个最佳参数下重新跑一遍 LOOCV 预测\n",
    "print(\"\\n正在生成最终预测结果...\")\n",
    "y_pred_svr = cross_val_predict(best_svr, X, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "# 计算指标\n",
    "r2 = r2_score(y, y_pred_svr)\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred_svr))\n",
    "\n",
    "print(f\"\\n=== SVR (调优后) 结果 ===\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# --- 5. 绘图: 预测值 vs 真实值 ---\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y, y_pred_svr, c='darkorange', alpha=0.7, edgecolors='k', s=60, label='SVR Prediction')\n",
    "# 画对角线\n",
    "min_val, max_val = min(y.min(), y_pred_svr.min()), max(y.max(), y_pred_svr.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', linewidth=2, label='Perfect Fit')\n",
    "\n",
    "plt.title(f\"Optimized SVR Prediction\\nR2={r2:.2f}, RMSE={rmse:.2f}\")\n",
    "plt.xlabel(\"Measured Tensile Strength\")\n",
    "plt.ylabel(\"Predicted Tensile Strength\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4168c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. 计算特征重要性 (Permutation Importance) ---\n",
    "# 必须使用拟合好的最佳模型\n",
    "best_svr.fit(X, y)\n",
    "\n",
    "print(\"正在计算 SVR 的特征重要性 (Permutation)...\")\n",
    "# n_repeats=30 意味着每个特征打乱30次来测试稳定性\n",
    "result = permutation_importance(best_svr, X, y, n_repeats=30, random_state=42, scoring='r2')\n",
    "\n",
    "# 整理结果\n",
    "perm_sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "\n",
    "print(\"\\n[SVR 特征重要性排行 (基于 R2 损失)]\")\n",
    "top_features = []\n",
    "for i in perm_sorted_idx:\n",
    "    name = features[i]\n",
    "    score = result.importances_mean[i]\n",
    "    # 只显示正贡献的特征\n",
    "    if score > 0:\n",
    "        print(f\"{name}: {score:.4f}\")\n",
    "        top_features.append((name, score))\n",
    "\n",
    "# --- 7. 绘图: 特征重要性柱状图 ---\n",
    "features_plot = [x[0] for x in top_features]\n",
    "scores_plot = [x[1] for x in top_features]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(features_plot)), scores_plot, color='darkorange', alpha=0.7)\n",
    "plt.xticks(range(len(features_plot)), features_plot, rotation=45, ha='right')\n",
    "plt.title(\"Feature Importance for SVR (Permutation)\", fontsize=14)\n",
    "plt.ylabel(\"Decrease in R2 Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0735a349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KRR\n",
    "target_col = 'tensile_strength'\n",
    "features = features_mech\n",
    "X, y = get_clean_data(target_col, features, df)\n",
    "\n",
    "# --- 2. 定义参数网格 ---\n",
    "# alpha: 正则化项。类似于 SVR 的 1/C。\n",
    "# gamma: RBF 核的宽度。\n",
    "param_grid = {\n",
    "    'kernelridge__alpha': [1e-3, 1e-2, 0.04, 0.05, 0.1, 1, 10],   # 正则化强度\n",
    "    'kernelridge__gamma': [1e-3, 1e-2, 0.1, 0.5, 1, 5] # 核函数敏感度\n",
    "}\n",
    "\n",
    "# --- 3. 网格搜索 (GridSearchCV) ---\n",
    "pipe = make_pipeline(StandardScaler(), KernelRidge(kernel='rbf'))\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid, \n",
    "    cv=LeaveOneOut(), # 保持一致，使用留一法\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_krr = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"\\n[最佳参数组合]\")\n",
    "print(best_params)\n",
    "\n",
    "# --- 4. 使用最佳参数进行最终预测 (LOOCV) ---\n",
    "# 再次跑一遍 LOOCV 以获取真实的泛化分数\n",
    "print(\"\\n正在生成最终预测结果...\")\n",
    "y_pred_krr = cross_val_predict(best_krr, X, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "# 计算指标\n",
    "r2 = r2_score(y, y_pred_krr)\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred_krr))\n",
    "\n",
    "print(f\"\\n=== KRR (调优后) 结果 ===\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# --- 5. 绘图: 预测值 vs 真实值 ---\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y, y_pred_krr, c='forestgreen', alpha=0.7, edgecolors='k', s=60, label='KRR Prediction')\n",
    "# 画对角线\n",
    "min_val, max_val = min(y.min(), y_pred_krr.min()), max(y.max(), y_pred_krr.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', linewidth=2, label='Perfect Fit')\n",
    "\n",
    "plt.title(f\"Optimized KRR Prediction\\nR2={r2:.2f}, RMSE={rmse:.2f}\")\n",
    "plt.xlabel(\"Measured Tensile Strength\")\n",
    "plt.ylabel(\"Predicted Tensile Strength\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf15e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. 计算特征重要性 (Permutation Importance) ---\n",
    "# 必须先全量拟合一次最佳模型\n",
    "best_krr.fit(X, y)\n",
    "\n",
    "print(\"正在计算 KRR 的特征重要性 (Permutation)...\")\n",
    "result = permutation_importance(best_krr, X, y, n_repeats=30, random_state=42, scoring='r2')\n",
    "\n",
    "# 整理结果\n",
    "perm_sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "\n",
    "print(\"\\n[KRR 特征重要性排行 (基于 R2 损失)]\")\n",
    "top_features_krr = []\n",
    "for i in perm_sorted_idx:\n",
    "    name = features[i]\n",
    "    score = result.importances_mean[i]\n",
    "    # 只显示正贡献的特征\n",
    "    if score > 0:\n",
    "        print(f\"{name}: {score:.4f}\")\n",
    "        top_features_krr.append((name, score))\n",
    "\n",
    "# --- 7. 绘图: 特征重要性柱状图 ---\n",
    "features_plot = [x[0] for x in top_features_krr]\n",
    "scores_plot = [x[1] for x in top_features_krr]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(features_plot)), scores_plot, color='forestgreen', alpha=0.7)\n",
    "plt.xticks(range(len(features_plot)), features_plot, rotation=45, ha='right')\n",
    "plt.title(\"Feature Importance for KRR (Permutation)\", fontsize=14)\n",
    "plt.ylabel(\"Decrease in R2 Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de3c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "target_col = 'tensile_strength'\n",
    "features = features_mech\n",
    "X, y = get_clean_data(target_col, features, df)\n",
    "\n",
    "# --- 2. 定义参数网格 ---\n",
    "# 这是一个针对小样本优化的搜索空间\n",
    "param_grid = {\n",
    "    'mlpregressor__hidden_layer_sizes': [(32,), (64,), (32, 16), (64, 32)], # 尝试更简单的结构\n",
    "    'mlpregressor__activation': ['relu', 'tanh'],  # tanh 对回归任务有时更平滑\n",
    "    'mlpregressor__solver': ['lbfgs', 'adam'],     # lbfgs 是小样本的关键！\n",
    "    'mlpregressor__alpha': [0.0001, 0.001, 0.01, 0.1], # 正则化力度\n",
    "    'mlpregressor__learning_rate_init': [0.001, 0.01]  # 初始学习率\n",
    "}\n",
    "\n",
    "# --- 3. 网格搜索 (GridSearchCV) ---\n",
    "# 定义 Pipeline (必须标准化！)\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    MLPRegressor(max_iter=5000, random_state=42) # 增加迭代次数防止不收敛\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid, \n",
    "    cv=LeaveOneOut(), # 保持一致，使用留一法\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_ann = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"\\n[最佳参数组合]\")\n",
    "print(best_params)\n",
    "\n",
    "# --- 4. 使用最佳参数进行最终预测 (LOOCV) ---\n",
    "print(\"\\n正在生成最终预测结果...\")\n",
    "y_pred_ann = cross_val_predict(best_ann, X, y, cv=LeaveOneOut(), n_jobs=-1)\n",
    "\n",
    "# 计算指标\n",
    "r2 = r2_score(y, y_pred_ann)\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred_ann))\n",
    "\n",
    "print(f\"\\n=== ANN (调优后) 结果 ===\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# --- 5. 绘图: 预测值 vs 真实值 ---\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y, y_pred_ann, c='mediumvioletred', alpha=0.7, edgecolors='k', s=60, label='ANN Prediction')\n",
    "# 画对角线\n",
    "min_val, max_val = min(y.min(), y_pred_ann.min()), max(y.max(), y_pred_ann.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', linewidth=2, label='Perfect Fit')\n",
    "\n",
    "plt.title(f\"Optimized ANN Prediction\\nR2={r2:.2f}, RMSE={rmse:.2f}\")\n",
    "plt.xlabel(\"Measured Tensile Strength\")\n",
    "plt.ylabel(\"Predicted Tensile Strength\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c8af90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. 计算特征重要性 (Permutation Importance) ---\n",
    "# 必须先全量拟合一次最佳模型\n",
    "best_ann.fit(X, y)\n",
    "\n",
    "print(\"正在计算 ANN 的特征重要性 (Permutation)...\")\n",
    "result = permutation_importance(best_ann, X, y, n_repeats=30, random_state=42, scoring='r2')\n",
    "\n",
    "# 整理结果\n",
    "perm_sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "\n",
    "print(\"\\n[ANN 特征重要性排行 (基于 R2 损失)]\")\n",
    "top_features_ann = []\n",
    "for i in perm_sorted_idx:\n",
    "    name = features[i]\n",
    "    score = result.importances_mean[i]\n",
    "    if score > 0: # 只显示正贡献\n",
    "        print(f\"{name}: {score:.4f}\")\n",
    "        top_features_ann.append((name, score))\n",
    "\n",
    "# --- 7. 绘图: 特征重要性柱状图 ---\n",
    "features_plot = [x[0] for x in top_features_ann]\n",
    "scores_plot = [x[1] for x in top_features_ann]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(features_plot)), scores_plot, color='mediumvioletred', alpha=0.7)\n",
    "plt.xticks(range(len(features_plot)), features_plot, rotation=45, ha='right')\n",
    "plt.title(\"Feature Importance for ANN (Permutation)\", fontsize=14)\n",
    "plt.ylabel(\"Decrease in R2 Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a3e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多模型能力横向对比\n",
    "models_dict = {\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=500, max_depth=30,min_samples_split=5,   random_state=42,n_jobs=-1),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100,learning_rate=0.02,max_depth=5,subsample=0.7,colsample_bytree=0.8,random_state=42,n_jobs=-1),\n",
    "    \"SVR\": make_pipeline(StandardScaler(), SVR(C=500, gamma=1.0,epsilon=0.1)),\n",
    "    \"GPR\": make_pipeline(StandardScaler(),GaussianProcessRegressor(kernel=1.0*Matern(length_scale=1.0, length_scale_bounds=(1e-2,1e2), nu=2.5)+ WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-5,1e1)),\n",
    "        n_restarts_optimizer=10,\n",
    "        random_state=42,\n",
    "        normalize_y=True)),\n",
    "    \"ANN (MLP)\": make_pipeline(StandardScaler(), MLPRegressor(hidden_layer_sizes=(64,),activation='tanh',learning_rate_init=0.001, max_iter=2000, alpha=0.01, random_state=42, solver='lbfgs',)),\n",
    "    \"KRR\": make_pipeline(StandardScaler(), KernelRidge(kernel='rbf', gamma=0.1,alpha=0.04))\n",
    "}\n",
    "\n",
    "# 设置要预测的目标\n",
    "current_target = 'tensile_strength' # 可修改为 'elongation' 或 'healing_eff'\n",
    "# 自动选择特征集\n",
    "current_features = features_heal if current_target == 'healing_eff' else features_mech\n",
    "\n",
    "# 获取数据\n",
    "X, y = get_clean_data(current_target, current_features, df)\n",
    "print(f\"正在对比所有模型，预测目标: {current_target} (样本数: {len(y)})...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "    r2, rmse, _ = evaluate_model(model, X, y)\n",
    "    results.append({\"Model\": name, \"R2\": r2, \"RMSE\": rmse})\n",
    "    print(f\" -> {name} 完成: R2={r2:.3f}\")\n",
    "\n",
    "# ---------- 将结果转为 DataFrame 并按 R2 排序 ----------\n",
    "res_df = pd.DataFrame(results).sort_values(by=\"R2\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 显示排序后的表格（可选）\n",
    "print(\"\\n排序后的模型性能：\")\n",
    "print(res_df)\n",
    "\n",
    "# --- 绘图部分（保证柱状图与折线顺序一致） ---\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# 用数值位置作为 x 轴（0..n-1）\n",
    "x_pos = np.arange(len(res_df))\n",
    "\n",
    "# 柱状图：R2\n",
    "bars = ax1.bar(x_pos, res_df['R2'], alpha=0.85, width=0.6)\n",
    "ax1.set_xlabel(\"Model\", fontsize=12)\n",
    "ax1.set_ylabel(\"R2 Score (Higher is Better)\", fontsize=12)\n",
    "ax1.set_ylim(0, 1.05)  # R2 一般在 0-1 之间（可根据实际调整）\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(res_df['Model'], rotation=30, ha='right', fontsize=11)\n",
    "\n",
    "# 在每个柱子上加数值注释\n",
    "for i, r2 in enumerate(res_df['R2']):\n",
    "    ax1.text(i, r2 + 0.02, f\"{r2:.2f}\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 右侧 y 轴绘制 RMSE 折线（与柱子位置一一对应）\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x_pos, res_df['RMSE'], marker='o', linewidth=2, linestyle='-', label='RMSE')\n",
    "ax2.set_ylabel(\"RMSE (Lower is Better)\", fontsize=12)\n",
    "# 可根据 RMSE 范围微调 ylimits，例如：\n",
    "rmse_min, rmse_max = res_df['RMSE'].min(), res_df['RMSE'].max()\n",
    "pad = (rmse_max - rmse_min) * 0.15 if rmse_max != rmse_min else 1.0\n",
    "ax2.set_ylim(rmse_min - pad, rmse_max + pad)\n",
    "\n",
    "# 在折线上每个点标注 RMSE 值\n",
    "for i, rmse in enumerate(res_df['RMSE']):\n",
    "    ax2.text(i, rmse + (pad * 0.03), f\"{rmse:.2f}\", ha='center', va='bottom', color='red')\n",
    "\n",
    "# 标题与样式\n",
    "plt.title(f\"Model Comparison for {current_target}\", fontsize=14)\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 打印详细排名表（已按 R2 排序）\n",
    "print(\"\\n详细排名：\")\n",
    "print(res_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_TEST1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
